# Домашнее задание к занятию «Микросервисы: подходы». Osipenkov AU

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;  
- система контроля версий Git;  
- репозиторий на каждый сервис;  
- запуск сборки по событию из системы контроля версий;  
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### Решение

Хранение исходного кода
---
- облачная система;  
**yandex cloud предоставляет облачные услуги разных направлений в том чилсе запуск сервера через Terraform или Ansbile**
- система контроля версий Git;  
**GitHub позволяет создавать и откатывать версии репозиториев**
- репозиторий на каждый сервис;  
**GitHub предоставялет хранение исходного кода репозитория и запуск его на виртуальной машине**

Непрерывная интеграция
---
- запуск сборки по событию из системы контроля версий;    
**Связка Terraform для запуска ВМ и Ansible для запуска Nexus (хранение версий артефактов .jar). GitHub для сохранения изменений репозитория.**
- запуск сборки по кнопке с указанием параметров;  
**Связка Terraform для запуска ВМ и Ansible или Docker**
- возможность привязать настройки к каждой сборке;  
**Связка Terraform для запуска ВМ и Ansible или Docker**
- возможность создания шаблонов для различных конфигураций сборок;  
**Связка Terraform для запуска ВМ и Docker**
- возможность безопасного хранения секретных данных (пароли, ключи доступа);  
**В Terraform применять файлы с данными в формате personal.auto.tfvars**
- несколько конфигураций для сборки из одного репозитория;  
**Docker или Ansible**
- кастомные шаги при сборке;  
**Docker или Ansible**
- собственные докер-образы для сборки проектов;  
**Dockerfile для DockerHUB**

Непрерывная поставка
---
- возможность развернуть агентов сборки на собственных серверах;  
**Связка Vagrant для запуска ВМ (сервера) и Ansible для запуска Nexus (хранение версий артефактов .jar) с Teamcity (агент сборки). GitHub для сохранения изменений репозитория**
- возможность параллельного запуска нескольких сборок;  
**Cвязка Vagrant для запуска ВМ и Ansbile для сборки сценариев**
- возможность параллельного запуска тестов.  
**Связка  Vagrant для запуска ВМ и Ansible или Docker для запуска Nexus (управление зависимостями) и Jenkins (непрерывный запуск тестов)**

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;  
**Filebeat**
- минимальные требования к приложениям, сбор логов из stdout;
**Filebeat**
- гарантированная доставка логов до центрального хранилища;

- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.
**Kibana
Обоснуйте свой выбор.

### Решение

- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;    
**Filebeat - сбор логов и отправка в logstash**
- минимальные требования к приложениям, сбор логов из stdout;  
**Logstash - сбор логов из stdout и отправка в БД elasticsearch**
- гарантированная доставка логов до центрального хранилища;  
**Elasticsearch - база данных для поиска логов**
- обеспечение поиска и фильтрации по записям логов;  
**Kibana - визуализация данных (хранение, фильтрация, доступ и поиск)**
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;  
**Kibana - визуализация данных (хранение, фильтрация, доступ и поиск)**
- возможность дать ссылку на сохранённый поиск по записям логов.  
**Kibana - визуализация данных (хранение, фильтрация, доступ и поиск)**

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### Решение

- сбор метрик со всех хостов, обслуживающих систему;  
**Prometheus-server - собирает метрику с ВМ и Prometheus node-exporter передает в Grafana**
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;  
**Prometheus-server - собирает метрику с ВМ и Prometheus node-exporter передает в Grafana**
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;  
**Prometheus-server - собирает метрику с ВМ и Prometheus node-exporter передает в Grafana**
- сбор метрик, специфичных для каждого сервиса;  
**Prometheus-server - собирает метрику с ВМ и Prometheus node-exporter передает в Grafana**
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
**Grafana - интерфейс метрик полученных от Prometheus node-exporter**
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.
**Grafana - интерфейс метрик полученных от Prometheus node-exporter**


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
